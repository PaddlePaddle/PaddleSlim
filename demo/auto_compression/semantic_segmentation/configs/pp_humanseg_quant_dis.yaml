Distillation:
  distill_lambda: 1.0
  distill_loss: l2_loss
  distill_node_pair:
  - teacher_reshape2_1.tmp_0
  - reshape2_1.tmp_0
  - teacher_reshape2_3.tmp_0
  - reshape2_3.tmp_0
  - teacher_reshape2_5.tmp_0
  - reshape2_5.tmp_0
  - teacher_reshape2_7.tmp_0 #block1
  - reshape2_7.tmp_0
  - teacher_reshape2_9.tmp_0
  - reshape2_9.tmp_0
  - teacher_reshape2_11.tmp_0
  - reshape2_11.tmp_0
  - teacher_reshape2_13.tmp_0
  - reshape2_13.tmp_0
  - teacher_reshape2_15.tmp_0
  - reshape2_15.tmp_0
  - teacher_reshape2_17.tmp_0
  - reshape2_17.tmp_0
  - teacher_reshape2_19.tmp_0
  - reshape2_19.tmp_0
  - teacher_reshape2_21.tmp_0
  - reshape2_21.tmp_0
  - teacher_depthwise_conv2d_14.tmp_0 # block2
  - depthwise_conv2d_14.tmp_0
  - teacher_depthwise_conv2d_15.tmp_0
  - depthwise_conv2d_15.tmp_0
  - teacher_reshape2_23.tmp_0 #block3
  - reshape2_23.tmp_0
  - teacher_relu_30.tmp_0 # final_conv
  - relu_30.tmp_0 
  - teacher_bilinear_interp_v2_1.tmp_0
  - bilinear_interp_v2_1.tmp_0
  merge_feed: true
  teacher_model_dir: ./inference_model
  teacher_model_filename: inference.pdmodel
  teacher_params_filename: inference.pdiparams
Quantization:
  activation_bits: 8
  is_full_quantize: false
  not_quant_pattern:
  - skip_quant
  quantize_op_types:
  - conv2d
  - depthwise_conv2d
  weight_bits: 8
TrainConfig:
  epochs: 1
  eval_iter: 400
  learning_rate: 0.0005
  optimizer: SGD
  optim_args:
    weight_decay: 4.0e-05