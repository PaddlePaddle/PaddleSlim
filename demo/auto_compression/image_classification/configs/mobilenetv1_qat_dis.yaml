Distillation:
  alpha: 1.0
  loss: l2
  node:
  - softmax_0.tmp_0
Quantization:
  activation_bits: 8
  is_full_quantize: false
  activation_quantize_type: range_abs_max
  weight_quantize_type: abs_max
  not_quant_pattern:
  - skip_quant
  quantize_op_types:
  - conv2d
  - depthwise_conv2d
  weight_bits: 8
TrainConfig:
  epochs: 1
  eval_iter: 500
  learning_rate: 0.004
  optimizer_builder:
    optimizer: 
      type: Momentum
    weight_decay: 0.00003
  origin_metric: 0.70898
