{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像分类模型量化训练-快速开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该教程以图像分类模型MobileNetV1为例，说明如何快速使用PaddleSlim的[量化训练接口](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/docs/api/quantization_api.md)。 该示例包含以下步骤：\n",
    "\n",
    "1. 导入依赖\n",
    "2. 构建模型\n",
    "3. 训练模型\n",
    "4. 量化\n",
    "5. 训练和测试量化后的模型\n",
    "6. 保存量化后的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入依赖\n",
    "PaddleSlim依赖Paddle1.7版本，请确认已正确安装Paddle，然后按以下方式导入Paddle和PaddleSlim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddleslim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建网络\n",
    "该章节构造一个用于对MNIST数据进行分类的分类模型，选用`MobileNetV1`，并将输入大小设置为`[1, 28, 28]`，输出类别数为10。               为了方便展示示例，我们在`paddleslim.models`下预定义了用于构建分类模型的方法，执行以下代码构建分类模型：\n",
    "\n",
    ">注意：paddleslim.models下的API并非PaddleSlim常规API，是为了简化示例而封装预定义的一系列方法，比如：模型结构的定义、Program的构建等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe, train_program, val_program, inputs, outputs = \\\n",
    "    slim.models.image_classification(\"MobileNet\", [1, 28, 28], 10, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练模型\n",
    "该章节介绍了如何定义输入数据和如何训练和测试分类模型。先训练分类模型的原因是量化训练过程是在训练好的模型上进行的，也就是说是在训练好的模型的基础上加入量化反量化op之后，用小学习率进行参数微调。\n",
    "\n",
    "### 3.1 定义输入数据\n",
    "\n",
    "为了快速执行该示例，我们选取简单的MNIST数据，Paddle框架的`paddle.dataset.mnist`包定义了MNIST数据的下载和读取。\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.dataset.mnist as reader\n",
    "train_reader = paddle.batch(\n",
    "        reader.train(), batch_size=128, drop_last=True)\n",
    "test_reader = paddle.batch(\n",
    "        reader.train(), batch_size=128, drop_last=True)\n",
    "train_feeder = fluid.DataFeeder(inputs, fluid.CPUPlace())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 训练和测试\n",
    "先定义训练和测试函数，正常训练和量化训练时只需要调用函数即可。在训练函数中执行了一个epoch的训练，因为MNIST数据集数据较少，一个epoch就可将top1精度训练到95%以上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(prog):\n",
    "    iter = 0\n",
    "    for data in train_reader():\n",
    "        acc1, acc5, loss = exe.run(prog, feed=train_feeder.feed(data), fetch_list=outputs)\n",
    "        if iter % 100 == 0:\n",
    "            print('train iter={}, top1={}, top5={}, loss={}'.format(iter, acc1.mean(), acc5.mean(), loss.mean()))\n",
    "        iter += 1\n",
    "        \n",
    "def test(prog):\n",
    "    iter = 0\n",
    "    res = [[], []]\n",
    "    for data in train_reader():\n",
    "        acc1, acc5, loss = exe.run(prog, feed=train_feeder.feed(data), fetch_list=outputs)\n",
    "        if iter % 100 == 0:\n",
    "            print('test iter={}, top1={}, top5={}, loss={}'.format(iter, acc1.mean(), acc5.mean(), loss.mean()))\n",
    "        res[0].append(acc1.mean())\n",
    "        res[1].append(acc5.mean())\n",
    "        iter += 1\n",
    "    print('final test result top1={}, top5={}'.format(np.array(res[0]).mean(), np.array(res[1]).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用``train``函数训练分类网络，``train_program``是在第2步：构建网络中定义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iter=0, top1=0.1171875, top5=0.546875, loss=2.79680204391\n",
      "train iter=100, top1=0.9296875, top5=1.0, loss=0.305284500122\n",
      "train iter=200, top1=0.9609375, top5=0.9921875, loss=0.158525630832\n",
      "train iter=300, top1=0.9609375, top5=0.9921875, loss=0.146427512169\n",
      "train iter=400, top1=0.9609375, top5=1.0, loss=0.179066047072\n"
     ]
    }
   ],
   "source": [
    "train(train_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用``test``函数测试分类网络，``val_program``是在第2步：构建网络中定义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test iter=0, top1=0.96875, top5=1.0, loss=0.0801232308149\n",
      "test iter=100, top1=0.9609375, top5=1.0, loss=0.104892581701\n",
      "test iter=200, top1=0.96875, top5=1.0, loss=0.156774014235\n",
      "test iter=300, top1=0.984375, top5=1.0, loss=0.0931615754962\n",
      "test iter=400, top1=0.9453125, top5=1.0, loss=0.184863254428\n",
      "final test result top1=0.970469415188, top5=0.999282181263\n"
     ]
    }
   ],
   "source": [
    "test(val_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 量化\n",
    "\n",
    "按照[默认配置](https://paddlepaddle.github.io/PaddleSlim/api/quantization_api/#_1)在``train_program``和``val_program``中加入量化和反量化op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-06 09:08:49,489-INFO: quant_aware config {'moving_rate': 0.9, 'weight_quantize_type': 'channel_wise_abs_max', 'is_full_quantize': False, 'dtype': 'int8', 'weight_bits': 8, 'window_size': 10000, 'activation_bits': 8, 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'not_quant_pattern': ['skip_quant'], 'activation_quantize_type': 'moving_average_abs_max', 'for_tensorrt': False}\n",
      "2020-02-06 09:08:50,943-INFO: quant_aware config {'moving_rate': 0.9, 'weight_quantize_type': 'channel_wise_abs_max', 'is_full_quantize': False, 'dtype': 'int8', 'weight_bits': 8, 'window_size': 10000, 'activation_bits': 8, 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'not_quant_pattern': ['skip_quant'], 'activation_quantize_type': 'moving_average_abs_max', 'for_tensorrt': False}\n"
     ]
    }
   ],
   "source": [
    "quant_program = slim.quant.quant_aware(train_program, exe.place, for_test=False)\n",
    "val_quant_program = slim.quant.quant_aware(val_program, exe.place, for_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练和测试量化后的模型\n",
    "微调量化后的模型，训练一个epoch后测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iter=0, top1=0.953125, top5=1.0, loss=0.184170544147\n",
      "train iter=100, top1=0.96875, top5=1.0, loss=0.0945074558258\n",
      "train iter=200, top1=0.9765625, top5=1.0, loss=0.0915599390864\n",
      "train iter=300, top1=0.9765625, top5=1.0, loss=0.0562560297549\n",
      "train iter=400, top1=0.9609375, top5=1.0, loss=0.094195574522\n"
     ]
    }
   ],
   "source": [
    "train(quant_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试量化后的模型，和``3.2 训练和测试``中得到的测试结果相比，精度相近，达到了无损量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test iter=0, top1=0.984375, top5=1.0, loss=0.0542894415557\n",
      "test iter=100, top1=0.9609375, top5=1.0, loss=0.0662319809198\n",
      "test iter=200, top1=0.9609375, top5=1.0, loss=0.0832970961928\n",
      "test iter=300, top1=0.9921875, top5=1.0, loss=0.0262515246868\n",
      "test iter=400, top1=0.96875, top5=1.0, loss=0.123742781579\n",
      "final test result top1=0.984057843685, top5=0.999799668789\n"
     ]
    }
   ],
   "source": [
    "test(val_quant_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 保存量化后的模型\n",
    "\n",
    "在``4. 量化``中使用接口``slim.quant.quant_aware``接口得到的模型只适合训练时使用，为了得到最终使用时的模型，需要使用[slim.quant.convert](https://paddlepaddle.github.io/PaddleSlim/api/quantization_api/#convert)接口，然后使用[fluid.io.save_inference_model](https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/api_cn/io_cn/save_inference_model_cn.html#save-inference-model)保存模型。``float_prog``的参数数据类型是float32，但是数据范围是int8, 保存之后可使用fluid或者paddle-lite加载使用，paddle-lite在使用时，会先将类型转换为int8。``int8_prog``的参数数据类型是int8, 保存后可看到量化后模型大小，不可加载使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-06 09:09:27,529-INFO: convert config {'moving_rate': 0.9, 'weight_quantize_type': 'channel_wise_abs_max', 'is_full_quantize': False, 'dtype': 'int8', 'weight_bits': 8, 'window_size': 10000, 'activation_bits': 8, 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'not_quant_pattern': ['skip_quant'], 'activation_quantize_type': 'moving_average_abs_max', 'for_tensorrt': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'save_infer_model/scale_0',\n",
       " u'save_infer_model/scale_1',\n",
       " u'save_infer_model/scale_2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_prog, int8_prog = slim.quant.convert(val_quant_program, exe.place, save_int8=True)\n",
    "target_vars = [float_prog.global_block().var(name) for name in outputs]\n",
    "fluid.io.save_inference_model(dirname='./inference_model/float',\n",
    "        feeded_var_names=[var.name for var in inputs],\n",
    "        target_vars=target_vars,\n",
    "        executor=exe,\n",
    "        main_program=float_prog)\n",
    "fluid.io.save_inference_model(dirname='./inference_model/int8',\n",
    "        feeded_var_names=[var.name for var in inputs],\n",
    "        target_vars=target_vars,\n",
    "        executor=exe,\n",
    "        main_program=int8_prog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
